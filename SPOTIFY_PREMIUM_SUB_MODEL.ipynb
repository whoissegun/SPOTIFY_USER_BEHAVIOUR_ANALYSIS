{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFxVIVTEQmEv",
        "outputId": "71ec2757-4f08-40ea-d9bd-b94a98ce26c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) #mounting my google drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "cHweciBpQ3ur"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/KAGGLE_API_CREDENTIALS/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "RhEno4G6Q5io"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "I18BmYdaQ7WI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import copy\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "FNff8678Rjtb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' #setting up device agnostic code"
      ],
      "metadata": {
        "id": "VcEyvc9gR6QJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d meeraajayakumar/spotify-user-behavior-dataset\n",
        "#link to dataset: https://www.kaggle.com/datasets/meeraajayakumar/spotify-user-behavior-dataset"
      ],
      "metadata": {
        "id": "fzOecXUKR8wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/spotify-user-behavior-dataset.zip"
      ],
      "metadata": {
        "id": "pwt0lkwJSfei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel('/content/Spotify_data.xlsx')\n",
        "\n",
        "df = df.dropna() #removing any row with an empty column\n"
      ],
      "metadata": {
        "id": "gmKB7-kgSoXp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "for col in df.columns: #applying label encoding on all columns except music_recc_rating since it's not categorical\n",
        "  if col != 'music_recc_rating':\n",
        "    df[col] = le.fit_transform(df[col])"
      ],
      "metadata": {
        "id": "R_SxHZaNWnSF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COLUMNS_TO_DROP = ['premium_sub_willingness','preffered_premium_plan'] #these are the columns I want the model to predict\n",
        "\n",
        "X = df.drop(COLUMNS_TO_DROP, axis=1)\n",
        "y1 = df['premium_sub_willingness']\n",
        "y2 = df['preffered_premium_plan']\n",
        "\n"
      ],
      "metadata": {
        "id": "VUga3FgWr4Ao"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_numpy = X.values\n",
        "\n",
        "\n",
        "X_train_prem_will, X_test_prem_will, y_train_prem_will, y_test_prem_will = train_test_split(X, y1, test_size=0.33, random_state=42)\n",
        "\n",
        "X_train_pref_plan, X_test_pref_plan, y_train_pref_plan, y_test_pref_plan = train_test_split(X, y2, test_size=0.33, random_state=42)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5bDP_g7cY6Nu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Convert the premium_sub_willingness data to PyTorch tensors\n",
        "X_train_prem_will_tensor = torch.Tensor(X_train_prem_will.values)\n",
        "y_train_prem_will_tensor = torch.Tensor(y_train_prem_will.values)\n",
        "X_test_prem_will_tensor = torch.Tensor(X_test_prem_will.values)\n",
        "y_test_prem_will_tensor = torch.Tensor(y_test_prem_will.values)\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_dataset_prem_will = TensorDataset(X_train_prem_will_tensor, y_train_prem_will_tensor)\n",
        "test_dataset_prem_will = TensorDataset(X_test_prem_will_tensor, y_test_prem_will_tensor)\n",
        "\n",
        "# Same for 'preffered_premium_plan'\n",
        "X_train_pref_plan_tensor = torch.Tensor(X_train_pref_plan.values)\n",
        "y_train_pref_plan_tensor = torch.Tensor(y_train_pref_plan.values)\n",
        "X_test_pref_plan_tensor = torch.Tensor(X_test_pref_plan.values)\n",
        "y_test_pref_plan_tensor = torch.Tensor(y_test_pref_plan.values)\n",
        "\n",
        "y_train_pref_plan_tensor = y_train_pref_plan_tensor.type(torch.LongTensor) #these are feature for multiclass model. sunce we're using cross entropy loss, their data type has to be changed to long\n",
        "y_test_pref_plan_tensor = y_test_pref_plan_tensor.type(torch.LongTensor)\n",
        "\n",
        "\n",
        "train_dataset_pref_plan = TensorDataset(X_train_pref_plan_tensor, y_train_pref_plan_tensor)\n",
        "test_dataset_pref_plan = TensorDataset(X_test_pref_plan_tensor, y_test_pref_plan_tensor)\n"
      ],
      "metadata": {
        "id": "-r4JjgpGfmBg"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader_prem_will = DataLoader(train_dataset_prem_will, batch_size=batch_size, shuffle=True)\n",
        "test_loader_prem_will = DataLoader(test_dataset_prem_will, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "train_loader_pref_plan = DataLoader(train_dataset_pref_plan, batch_size=batch_size, shuffle=True)\n",
        "test_loader_pref_plan = DataLoader(train_dataset_pref_plan, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "d2BE7Yweirla"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PremiumPlanSubscriptionPredictorV3(nn.Module):\n",
        "  def __init__(self, input_shape, output_shape):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Linear(in_features=input_shape, out_features=64),\n",
        "        nn.BatchNorm1d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.45),  # Add dropout layer with 20% dropout rate\n",
        "        nn.Linear(in_features=64, out_features=128),\n",
        "        nn.BatchNorm1d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.45),  # Add dropout layer with 20% dropout rate\n",
        "        nn.Linear(in_features=128, out_features=32),\n",
        "        nn.BatchNorm1d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.45),  # Add dropout layer with 20% dropout rate\n",
        "        nn.Linear(in_features=32, out_features=18),\n",
        "        nn.BatchNorm1d(18),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.45),  # Add dropout layer with 20% dropout rate\n",
        "        nn.Linear(in_features=18, out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.layer_stack(X).squeeze(dim=1)\n"
      ],
      "metadata": {
        "id": "LdZdv-IAfgIR"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PremiumPlanSubscriptionAmountPredictorV1(nn.Module):\n",
        "  def __init__(self,input_shape,output_shape):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Linear(in_features=input_shape, out_features=64),\n",
        "        nn.BatchNorm1d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(in_features=64, out_features=128),\n",
        "        nn.BatchNorm1d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(in_features=128, out_features=64),\n",
        "        nn.BatchNorm1d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(in_features=64, out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self,X):\n",
        "    return self.layer_stack(X)\n"
      ],
      "metadata": {
        "id": "aHNCHXblYfqf"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = PremiumPlanSubscriptionPredictorV3(input_shape=X.shape[1], output_shape=1).to(device)\n",
        "model_1 = PremiumPlanSubscriptionAmountPredictorV1(input_shape=X.shape[1], output_shape=len(y2.unique())).to(device)"
      ],
      "metadata": {
        "id": "i5nzJJe1wp37"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, loss_fn, optimizer,device ,model_type):\n",
        "    model.train()\n",
        "    running_loss = 0.0 #keeps track of the total loss in entire dataset\n",
        "    preds_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    for X, y in train_loader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X)\n",
        "        loss = loss_fn(outputs, y)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Get predictions\n",
        "        if model_type == 'binary':\n",
        "          preds = (outputs > 0).float()\n",
        "        else:\n",
        "          preds = torch.argmax(outputs,dim=1)\n",
        "\n",
        "        # Move predictions and labels to CPU and convert to numpy arrays, then append to the lists\n",
        "        preds_list.append(preds.detach().cpu().numpy())\n",
        "        labels_list.append(y.cpu().numpy())\n",
        "\n",
        "        running_loss += loss.item() * X.size(0)\n",
        "\n",
        "    # Concatenate all the numpy arrays into a single numpy array\n",
        "    all_preds = np.concatenate(preds_list, axis=0)\n",
        "    all_labels = np.concatenate(labels_list, axis=0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)  # Use scikit-learn's accuracy_score\n",
        "\n",
        "    return epoch_loss, epoch_acc\n"
      ],
      "metadata": {
        "id": "pCpEzYrjxSUd"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_loader, loss_fn, device, model_type):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    labels_list = []\n",
        "    preds_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "\n",
        "\n",
        "            outputs = model(X)\n",
        "            loss = loss_fn(outputs, y)\n",
        "\n",
        "            if model_type == 'binary':\n",
        "              preds = (outputs > 0).float()\n",
        "            else:\n",
        "              preds = torch.argmax(outputs,dim=1)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            labels_list += y.cpu().numpy().tolist()\n",
        "            preds_list += preds.cpu().numpy().tolist()\n",
        "\n",
        "    epoch_loss = running_loss / len(test_loader)\n",
        "    epoch_acc = accuracy_score(labels_list, preds_list)  # using sklearn's accuracy_score\n",
        "\n",
        "    classification_results = classification_report(labels_list, preds_list)\n",
        "\n",
        "    return epoch_loss, epoch_acc, classification_results\n"
      ],
      "metadata": {
        "id": "h-6_qJcs1k9E"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_validate(model, train_loader, test_loader, loss_fn, optimizer, epochs, device, model_type, model_save_path):\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        train_loss, train_acc = train_model(model, train_loader, loss_fn, optimizer, device,model_type)\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "          test_loss, test_acc, class_report = test_model(model, test_loader, loss_fn, device, model_type)\n",
        "          print(f'Epoch {epoch+1}/{epochs},test Loss: {test_loss:.4f}, test Acc: {test_acc:.4f}')\n",
        "\n",
        "\n",
        "        # Save the model weights if this epoch gives us the highest test accuracy\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            torch.save(model.state_dict(), model_save_path)\n",
        "            best_class_report = class_report\n",
        "            #print(best_class_report)\n",
        "\n",
        "    # After all epochs, print the best classification report\n",
        "    print(\"Best Classification Report : \")\n",
        "    return best_class_report, best_acc"
      ],
      "metadata": {
        "id": "ZTphx4EK3bB9"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model_0.parameters(), lr=0.008, weight_decay=0.003)\n",
        "epochs = 500\n",
        "model_type = 'binary'\n",
        "\n",
        "# Perform training and validation\n",
        "train_and_validate(model_0, train_loader_prem_will, test_loader_prem_will, loss_fn, optimizer, epochs, device, model_type, 'premium_plan_subscription_predictor_model_weights.pth')"
      ],
      "metadata": {
        "id": "RaXjbYi63k46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.load_state_dict(torch.load('/content/premium_plan_subscription_predictor_model_weights.pth'))\n",
        "model_1.load_state_dict(torch.load('/content/premium_plan_subscription_amount_predictor_model_weights.pth'))"
      ],
      "metadata": {
        "id": "hEwFm8Svq77b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}